% !TeX root=_main_.tex
% chapter1
% دستور زیر باید در اولین فصل شما باشد. آن را حذف نکنید!
\pagenumbering{arabic}

\chapter{مقدمه}\label{chapter1}
\thispagestyle{empty}


%\begin{flushright}
%\begin{displayquote}	
\epigraph{
«من می‌گویم، امنیت، بالاترین اولویت ماست؛ زیرا برای همه چیزهای هیجان‌انگیزی که شما قادر به انجام دادن آن با کامپیوترها هستید – سازمان‌دهی زندگی‌تان، در ارتباط ماندن با دیگران، خلاق بودن – اگر ما مسائل امنیتی را حل نکنیم، مردم از همه این‌ها عقب خواهند ماند.»
}
{$ \maltese $ {\large بیل گیتس}}
%\end{displayquote}
%\end{flushright}





\section{پیش‌زمینه}
در حـوزه مهندسی نرم‌افزار خودکار (\gls{ASE})،
%\footnote{\lr{automate software engineering}}
\index{مهندسی نرم‌افزار خودکار}
یکی از زمینه‌های مورد مطالعه و پژوهش، خودکارسازی فرایند آزمون نرم‌افزار، به‌عنوان یکی از مراحل مهم توسعه و ساخت یک سیستم نرم‌افزاری است. به‌طور کلی هدف از خودکارسازی، کاهش هزینه و زمان و افزایش دقت در اجرای یک فرایند است.
\gls{FuzzTesting}\index{آزمون!نرم‌افزار}\index{آزمون!فازی}
یکی از فنون آزمون خودکار نرم‌افزار است. آزمون فازی در یافتن
\gls{Fault}ها و\gls{Vulnerability} ها در نرم‌افزارهای دنیای واقعی مانند مرورگرهای وب، ویرایش‌گرهای متن، پخش‌کننده‌های چندرسـانه‌ای و غیره، بسیار مـؤثر واقع شده است
\cite{Takanen:2008:FSS:1404500, Sutton:2007:FBF:1324770}.
در این فن ورودی‌هایی
\gls{Malformed}
\index{بدشکل}
توسط یک برنامه دیگر، یعنی با روش خودکار، تولید شده و به نرم‌افزار تحت آزمون (\gls{SUT})
\index{نرم‌افزار تحت آزمون}
تزریق می‌شود.
\gls{SUT}
در عین حال، به امید یافتن خطا بر اثر پردازش ورودی تزریق شده، \gls{Monitor} می‌شود. ورودی تولید شده که به برنامه داده می‌شود، نقش
\textbf{\gls{TestData}}
\index{داده آزمون} 
را داشته و عامل اصلی نمایان‌سازی \gls{Fault}(های) احتمالی موجود در برنامه با بردن آن به یک حالت \gls{Failure}
\index{خرابی}
 است. به‌همین علّت مهم‌ترین مرحله در فرایند آزمون فازی \index{آزمون!فازی} را می‌توان تولید خودکار داده‌های آزمون دانست، به‌نحوی که بیشترین \gls{Fault}ها، ایراد‌ها و آسیب‌پذیری‌ها شناسایی گردند.





   
\section{شرح مسئله}\label{problem_statement}
راه‌کارهای مطرح در فن \gls{FuzzTesting}
\cite{Miller:1990:ESR:96267.96279,Miller1995,Forrester:2000:ESR:1267102.1267108,Miller:2006:ESR:1145735.1145743}،
برای شناسایی \gls{Fault}ها \index{خطا} و \gls{Vulnerability}‌ها \index{آسیب‌پذیری} نیازمند تولید تعداد زیادی \gls{TestData} هستند. در نرم‌افزارهایی با ساختار ورودی ساده، تولید داده آزمون نیز ساده است. برای مثال می‌توان با روش تصادفی این کار را انجام داد. اما در نرم‌افزارهایی با ساختار ورودی پیچیده، مانند فایل با قالب مشخص تولید داده آزمون متنوع که بتواند مسیرهای اجرایی بیشتری را پوشش دهد، کار آسانی نیست. تعداد و عمق مسیرهای اجرایی در یک برنامه با ساختار ورودی پیچیده به مراتب بیشتر از یک برنامه با ساختار ورودی ساده است. بررسی‌ها نشان می‌دهد بسیاری از داده‌های آزمون تولید شده برای چنین نرم‌افزارهایی، مسیرهای یکسان و سطحی (کم عمق) را می‌پیمایند
\cite{Rawat2017VUzzerAE}
و در مجموع، آزمون‌های فازی معمول پوشش کد ضعیفی دارند
\cite{Kargen:2015:TPA:2786805.2786844}.
درصد بالایی از داده‌های آزمون ساخته شده به‌صورت تصادفی، از لحاظ ساختاری کاملاً نامعتبر هستند و در همان مراحل اولیه بررسی صحت فایل، به‌وسیله \gls{Parser} ورودی برنامه هدف، رد می‌شوند
\cite{10.1007/978-3-319-45744-4_29, Rawat2017VUzzerAE}.
در چنین شرایطی، قادر به نفوذ به عمق برنامه، کشف و آزمایش مسیرهای جدید نخواهیم بود. در واقع این نوع ورودی‌ها به نوعی تکراری و هدر رفته محسوب می‌گردند.


برای حل مسائل بالا، داده آزمون را با استفاده از قالب یا گرامر ورودی تولید می‌کنند، روش‌هایی مثل 
\cite{Godefroid:2012:SWF:2090147.2094081}
. قالب یا گرامر اما به صورت دستی و از روی مستندات تهیه می‌شود که با توجه به پیچیده بودن ساختار آن، عملی زمان‌بر، پرهزینه و مستعد خطا است
\cite{Godefroid:2017:LML:3155562.3155573}.
همچنین مستندات ساختار ورودی همواره دردسترس آزمون‌گر نیست. با این اوصاف روش مذکور تا به امروز، یکی از مؤثرترین روش‌های آزمون و یافتن خطا در برنامه‌هایی مانند مرورگرهای وب بوده، که ساختار ورودی آن فایل‌هایی با قالب‌های متنوع و پیچیده هستند
\cite{Godefroid:2017:LML:3155562.3155573, Kettunen2014}.
به همین جهت، ارایه روشی برای خودکارسازی تولید داده آزمون بر مبنای قالب ورودی ارزشمند و حائز اهمیت است. پیش از ارایه یک روش جدید در ادامه ابتدا مسئله را دقیق‌تر تبیین کرده و راه‌حل‌های قبلی و نارسایی‌های هریک از آنها را مطالعه می‌کنیم.


\subsection{شهود اولیه}\label{intuition}
برای روشن شدن مسئله و شناسایی مشکلات موجود در تولید داده آزمون، مسئله را به زیر مسائل کوچک‌تر شکسته و از زوایای گوناگون تشریح می‌کنیم. ساختار پیچیده ورودی، ساختار پیچیده کد و تمایز داده و \gls{Metadata} سه زیر مسئله‌ای هستند که ما آنها را شناسایی کرده و در این بخش، مطرح می‌کنیم. در ادامه این پایان‌نامه تمرکز خود را بر روی حل این مسائل منعطف خواهیم کرد.


\subsubsection{ساختار پیچیده ورودی}
نخستین مورد حائز اهمیت ساختار ورودی برنامه است. در برنامه‌هایی با ورودی خط فرمان (\gls{CLI}) ساختارها به نسبت ساده هستند. اما برنامه‌هایی با ورودی فایل، ساختار ورودی بسیار پیچیده‌تری دارند. در واقع بسته به کاربرد، آنها یک یا چندین قالب فایل تعریف شده را پشتیبانی می‌کنند. همچنین برای یک قالب فایل شناخته‌شده ممکن است چندین نرم‌افزار وجود داشته‌ باشد. یعنی در حالت کلی یک ارتباط چند‌به‌چند بین قالب فایل ورودی و نرم‌افزار
وجود دارد. هنگامی که یک نرم‌افزار برای آزمون انتخاب می‌شود هریک از قالب‌های فایلی که پشتیبانی ‌می‌کند بخشی از کد نرم‌افزار را اجرا خواهند کرد.

فایل \gls{PDF}
را می‌توان نمونه‌ای از یک ورودی پیچیده برای نرم‌افزارهای \gls{PDF}خوان، مثل اغلب مرورگرهای وب،  تلقی کرد. مجموعه اسناد توصیف کننده \glspl{Specification}ی کامل قالب \gls{PDF} بیش از 1300 صفحه است 
\cite{Godefroid:2017:LML:3155562.3155573}.
 جزئیات ساختار این قالب را در پیوست \ref{appendix:1} بیان کرده‌ایم. در ساختارهای پیچیده هر بایت و در مواردی هر بیت نقش ویژه‌ای ایفا می‌کند که تولید تصادفی آنها تنوعی در پوشش کد برنامه ایجاد نمی‌کند؛ زیرا اغلب در دام کدهای \gls{ExceptionHandling} می‌افتند. بنابراین داشتن یک درک حداقلی از ساختار در هنگام تولید داده جدید بسیار کمک کننده خواهد بود. چگونگی کسب این درک به‌صورت خودکار مسئله‌ای است که بایستی حل شود.



\subsubsection{ساختار پیچیده کد}
پیچیده بودن ساختار ورودی، منجربه پیچیده شدن کداجرایی و در نتیجه ممانعت از پوشش کد بالا در آزمون فازی خواهد شد. برای درک بهتر این مسئله برنامه 
\ref{codesnip1}
به زبان \lr{C} را درنظر می‌گیریم. به‌خاطر سرعت بالای اجرا، بیشتر تجزیه‌گرهای قالب‌های پیچیده به این زبان نوشته می‌شوند. این برنامه یک فایل را از ورودی خوانده و براساس بایت‌های مشخصی در آدرس نسبی آن، مسیرهای معینی را اجرا می‌کند. چندین نکته قابل توجه در قطعه کد مذکور وجود دارد
\cite{Rawat2017VUzzerAE}
:

\begin{enumerate}
	\item{
		\textbf{\glspl{MagicByte}:}
		بایت دوم و بایت اول ابتدا برای اعتبارسنجی ورودی با مقادیر ثابتی مقایسه می‌شوند. اگر نتیجه این مقایسه صحیح نباشد؛ ورودی درجا رد می‌شود. در سطر 13 این مثال ابتدا آدرسی نسبی 1 با مقدار 
		\lr{\textit{0xEF}}
		و سپس آدرس نسبی 0 با مقدار
		\lr{\textit{0xFD}}
		مقایسه می‌گردد. بایت‌های جادویی در قالب‌های فایل بسیاری وجود دارند. از جمله قالب فایل
		\lr{jpeg}
		که در ابزار
		\lr{djpeg}\LTRfootnote{\href{https://linux.die.net/man/1/djpeg}{https://linux.die.net/man/1/djpeg}}
		با همین روش، اعتبارسنجی می‌شود.
	}
	\item{
		\textbf{شرط‌های تودرتو:}
		در اجرای برنامه، هر مسیر اجرایی مهم است. هرچند رسیدن به برخی مسیرها ممکن است دشوارتر باشد یا حتی امکان‌پذیر نباشد
		\cite{ammann2016introduction}
		. در این مثال برای رسیدن به خط 18 کد بایستی همه شرایط موجود در خط 17 برقرار باشد که به‌نوبه خود نیاز هست تا شرط موجود در خط 15 نیز برقرار شد و به همین ترتیب. لذا داده آزمون تولیدی باید تا حد زیادی معتبر باشد تا بتواند به عمق مدنظر دسترسی پیدا کند.
	}
	\item{
		\textbf{\gls{Marker}}\textbf{ها:}
		برای رسیدن به کد خطادار در سطر 19 بایستی شرط سطر 18 ارضـا شود. این مقایسه با یک توالی از نشانه‌ها انجام می‌شود که آدرس نسبی شروع آن لزوماً ثابت نیست؛ البته در این مثال ثابت نشان داده شده است. در قالب‌های فایل‌هایی مانند
		\lr{png}،
		\lr{jpeg}
		و 
		\lr{gif}
		این قبیل نشان‌گرها دیده می‌شود.			
	}
	\item{
		\textbf{آدرس‌های نسبی متغیر:}
		برای رسیدن به مسیر اجرایی سطر 18 یک مقایسه برمبنای آدرس‌های نسبی در سطر 17 انجام می‌شود. آدرس نسبی به‌کار رفته در این مقایسه‌ها، از ورودی خوانده شده یا داخل برنامه محاسبه شده‌اند و بنابراین ممکن است که در هر بار اجرا متفاوت باشند. این امر برخلاف مورد بایت‌های جادویی است که آدرس نسبی ثابتی دارند.
	}
	
\end{enumerate}



%\begin{figure}%[ht]
	%\def\lstlistingname{\rl{تکه کد}}
	%\begin{lstlisting}[language=C]
\begin{LTR}
	\singlespacing
	\begin{lstlisting}[language=C, caption={\rl{یک قطعه‌کد به عنوان نمونه‌ای از نرم‌افزار تحت آزمون در این پایان‌نامه، با ساختار تودرتو که چالش‌های پیچیدگی برنامه تحت آزمون و پوشش کد در آزمون فازی قالب فایل را نشان می‌دهد \cite{Rawat2017VUzzerAE}(با تغییر).}}, label={codesnip1},lineskip=.05cm][ht]
	#include <stdio.h>
	void main(int argc, char *argv[]){
		unsigned char buffer[1024]; //Fixed size buffer
		int fd, size, i, j;
		/* Some initialization here */
		if((fd = open(argv[1], O_RDONLY)) == -1)
			exit(0);
		fstat(fd, &s);
		size = s.st_size;
		if(size > 1024)
			return -1;
		read(fd, buffer, size);
		if(buffer[1] == 0xEF && buffer[0] == 0xFD) //Complex logic expression
			printf("Magic bytes matched!\n");
		else
			EXIT_ERORR("Invalid input file\n");
		if(buffer[i] == '%' && buffer[j] == '$' ){
			if(strcmp(&buffer[15], "MAZE", 4) == 0) //Nested condition
				/* Codes contain bug here */
			else{
				/* *** Render file here (lines of code) *** */
				close(fd); 
				return 0;
				}
		else{
			EXIT_ERROR("Invalid bytes");
			close(fd);
			return 0;
			}
		close(fd);
	}\end{lstlisting}
	\doublespacing
\end{LTR}
%\end{figure}

%\begin{small}\noindent
	%یک قطعه‌کد با ساختار تودرتو که چالش‌های پیچیدگی برنامه و پوشش کد در آزمون فازی قالب فایل را نشان می‌دهد.%
%\end{small}



\subsubsection{ تمایز داده و فراداده}
	برنامه مبتنی بر ورودی فایل، به‌طور معمول دو گام مجزا را برای پردازش یک فایل طی می‌کند: گام اول \gls{Parse} فایل و گام دوم \gls{Render} آن. در مرحله \gls{Parse}، فایل در حافظه بارگذاری، مقادیر فیلدهای آن خوانده شده و تبدیل به داده‌ساختارهای داخل حافظه اصلی (مثل بافر، ساختمان یا رکورد، آرایه و غیره) می‌شود. در این مرحله چنان‌چه \gls{Error} نحوی در ساختار فایل باشد (فایل از مشخصه‌های قالب خود پیروی نکند)، باید توسط تجزیه‌گر تشخیص داده شود وگرنه منجربه اشکال \gls{MemoryCorruption} و خرابی برنامه می‌شود. در مرحله پرداخت، برنامه روی اطلاعات خوانده شده از فایل پردازش لازم را انجام می‌دهد و خروجی تولید می‌کند (مثلاً نمایش یک تصویر روی صفحه نمایش یا اجرای یک ویدئـو و غیره) \cite{Rathaus:2007:OSF:1536880}. خطاهای این مرحله معمولاً جدی‌تر بوده و تشخیص آن نیز مشکل‌تر است، زیرا در عمق بیشتری از کد اجرایی رخ می‌دهند. جایی که داده‌های آزمون کمتری به آن دست پیدا می‌کنند.
	
	
	با توجه به توضیح بالا، می‌توان یک فایل را حاوی دو دسته از مقادیر دانست: اول، مقادیری که مشخص کننده ساختار آن فایل هستند؛ برای مثال نام فیلد‌ها. این مقادیر را \gls{Metadata} یا دادگان (داده برای داده) می‌نامند. دوم، مقادیری که مشخص کننده اطلاعات هر فیلد هستند یا همان داده‌های فایل. مسئله نهفته در اینجا آن است که رویکرد آشکارسازی خطا برای هر کدام از این قسمت‌ها متفاوت خواهد بود؛ چراکه طبیعت خطاهای هر قسمت با یکدیگر متفاوت بوده و همان‌طور که گفته‌شد در مراحل مختلفی هم روی می‌دهند. برای آشکار کردن خطاهای تجزیه‌گر، لازم است تا فایل‌هایی تولید کنیم که بخش فراداده آن بدشکل شده‌اند در حالی که برای آشکار کردن خطاهای بخش پرداخت، بایستی فایل‌هایی تولید کنیم که از لحاظ نحوی معتبر بوده و بخش داده‌ آن بدشکل شده باشند. شرط لازم هر دو نوع بدشکل‌سازی داشتن سازوکاری برای تشخیص داده و فراداده از یکدیگر، در هنگام تولید داده‌های آزمون است.  
	
	همان‌طور که گفتیم، رسیدن به کدهای مرحله پرداخت یک فایل (منظور تزریق داده آزمونی است که منجربه اجرای آن شود) سخت‌تر است. در برنامه \ref{codesnip1}، فرض شده است که به عنوان مثال پرداخت فایل در خط 21 انجام می‌شود؛ یعنی، بعد از گذشتن از تمامی شرایط و بررسی‌های انجام شده توسط تجزیه‌گر و انتقال فیلد‌های داخلی فایل به حافظه اصلی (فیلدهایی مثل فیلد \lr{size} در برنامه مذکور). هر داده آزمونی که یکی از شرایط قبل از خط 21 را نداشته باشد، رد شده و آن اجرا از برنامه به اجرای خط 21 منتهی نمی‌گردد. برای آن که درصد خوبی از داده‌های آزمون تولید شده به اجرای خط 21 منجر شوند، بایستی یک فایل تقریباً معتبر و پیروی کننده از قواعد قالب فایل مورد انتظار برنامه \ref{codesnip1} را به عنوان داده آزمون تولید کرد. 
	
	آنچه از شهود داده شده در این قسمت نتیجه می‌شود آن است که از یک برنامه قابل اطمینان و غیر قابل نفوذ، انتظار می‌رود که تحت هیچ عنوان بر اثر پردازش یک ورودی دچار خطا نشود. تنها زمانی می‌توان این ادعا را داشت که مطمئن شویم برنامه ورودی‌های به اندازه کافی متنوع را پردازش کرده و در هیچکدام از آنها دچار خطا نشده است. ورودی‌ها بایستی قادر به اجرای بخش‌های زیادی از کد برنامه باشند. حالت ایده‌آل اجرای تمام کد یک برنامه پیچیده است.  
	
	 %برای روشن شدن این مسئله، مثال انگیزشی کد 1-2 را مطرح می‌کنیم.
	     
%در این پایان‌نامه روشی مبتنی بر مدل‌های زبانی عصبی برای تولید خودکار داده آزمون با استفاده از یادگیری آماری ساختار فایل ارائه می‌شود.


\subsection{کارهای مرتبط}
تعدادی کار در ارتباط با استخراج خودکار گرامر فایل انجام شده‌اند.
\lr{Bastani} 
و همکاران 
\cite{Bastani:2017:SPI:3140587.3062349}
الگوریتمی برای تولید یک گرامر مستقل از متن روی یک مجموعه از ورودی‌های نمونه داده شده ارایه کرده‌اند، که در نهایت برای تولید داده‌های جدید مورد نیاز آزمون فازی استفاده می‌شود. این الگوریتم یک مجموعه از مراحل تعمیم‌پذیری را با معرفی ساختارهای تکراری و متناوب برای عبارت‌های منظم به‌کار می‌بندد و غیر پایانه‌ها را برای گرامر مستقل از متن در هم ادغام می‌نماید که به‌نوبه خود یک گرامر یکنواخت از زبان ورودی به‌دست می‌دهد؛ اما، این روش برای قالب‌هایی مثل 
\lr{PDF}
 که ساختار مسطح (غیر تو در تو) ولی در عین حال محتوای مختلفی از انواع و جفت‌های کلید-مقدار دارند، مناسب نیست
 \cite{Godefroid:2017:LML:3155562.3155573}.
 
 
 \lr{AUTOGRAM} \cite{Hoschele:2016:MIG:2970276.2970321}
  نیز به‌صورت غیر-احتمالاتی یک گرامر مستقل از متن را یاد می‌گیرد. یک مجموعه ورودی داده‌شده و به‌صورت پویا مشخص می‌شود که چگونه ورودی‌ها در برنامه پردازش می‌شوند. در واقع برنامه تحت آزمون با آلودگی پویا  مشاهده می‌شود که حافظه را با قطعات ورودی که از آنها می‌آیند، برچسب‌گذاری می‌کند. بخش‌هایی از ورودی‌ها که توسط برنامه پردازش می‌شود، نهادهای نحوی در گرامر می‌شوند.  

در پژوهش‌های اخیر تمایل زیادی به استفاده از شبکه‌های عصبی برای تحلیل و تولید برنامه‌ها به‌وجود آمده‎‌است. در سال 2017، 
\lr{Godefroid} \cite{Godefroid:2017:LML:3155562.3155573}
و همکاران روش جدیدی را برای تولید داده آزمون جهت استفاده در آزمون فازی بر مبنای مدل کدگذار-کدگشا\LTRfootnote{\lr{Encoder-Decoder Model}}
 \cite{NIPS2014_5346, DBLP:journals/corr/ChoMGBSB14}
 ارایه کردند. در مقاله آنها، ساختار فایل 
\lr{PDF} 
برای آزمون انتخاب شده است. ایده اصلی یادگیری یک مدل مولد روی مجموعه‌ای از ویژگی‌های اشیای داده‌ای
\lr{PDF} 
  با داشتن مجموعه‌ای از نمونه‌های اولیه است. مدل کدگذار-کدگشا اجازه یادگیری متن با طول دلخواه را برای پیش‌بینی توالی بعدی کاراکترها، می‌دهد. 
  
  مدل استفاده شده توسط 
\lr{Godefroid}
و همکاران، مدل مبنایی وظایفی مانند ترجمه ماشینی یا تبدیل گفتار به نوشتار است که یادگیری ساختار فایل را نمی‌توان در این وظایف گنجاند؛ زیرا، این مدل‌ برای نگاشت دو توالی با دامنه‌های مختلف به کار گرفته می‌شود و این در حالی است که یادگیری ساختار فایل چنین وظیفه‌ای نیست. یعنی می‌توان از مدل‌های ساده‌تری مانند مدل زبانی نیز برای یادگیری ساختار فایل استفاده کرد. روش پیشنهادی آنها، تنها ساختارهای متنی فایل را مورد یادگیری قرار می‌دهد. این در حالی است که ساختار فایل‌های پیچیده هم متنی و هم دودویی هستند. افزون بر این، الگوریتم پیشنهادی آنها برای تولید داده آزمون نیز مشکلاتی دارد. از جمله اینکه ممکن است هیچ‌گاه پایان نیابد. در فصل \ref{related_work}، ضمن تشریح کامل این روش، مشکلات آن را نیز به‌صورت کامل‌تری بیان می‌کنیم. همچنین در فصل \ref{related_work}، دو فازر قالب فایل دیگر تحت عنوان
 \lr{AFL} \cite{Zalewsky2013}
  و
\lr{AFL}افزوده \cite{DBLP:journals/corr/abs-1711-04596}
 که با روش‌هایی غیر از یادگیری گرامر سعی در بهبود پوشش کد 
\gls{SUT}
در فرایند آزمون فازی را دارند، نیز بررسی می‌کنیم و مشکلات آنها را بیان خواهیم کرد.

در هیچ‌کدام از کارهای قبلی، مسئله مطرح شده در ارتباط با تمایز میان داده و فراداده در هنگام آزمون فازی دیده نشده است. به عبارت دیگر، این دیدگاه به آزمون فازی قالب فایل، دیدگاهی نو است و ارزش آزمایش شدن دارد.    امکان استفاده از الگوریتم ارایه شده در روش \cite{Godefroid:2017:LML:3155562.3155573}، برای تمایز میان داده و فراداده وجود دارد اما برای حل مابقی مشکلات، یک روش جدید را در فصل
\ref{ch:4}
، پیشنهاد خواهیم داد. 


\subsection{فرضیه‌ها و اهداف}
هدف اصلی در پایان‌نامه پیش‌ِرو، ارائه روشی کـارا جهت یافتن خطاها و آسیب‌پذیری‌ها در نرم‌افزارهایی مثل \gls{PDF}خوان‌ها بوده که ورودی آنها فایل با ساختار مشخص و معمولاً پیچیده است. در این راستا تولید خودکار فایل‌های ورودی با هدف افزایش \gls{CodeCoverage} \gls{SUT} از اهمیت ویژه‌ای برخوردار است. برای نیل بدین اهداف از فنون \gls{DeepLearning} در یادگیری و درک خودکار ساختار فایل و سپس تولید فایل‌های جدید، استفاده خواهیم کرد. 

چون ایده استفاده از یادگیری ماشینی در آزمون فازی جدید است، این حوزه هنوز برای پژوهشگران ناشناخته  بوده و بنابراین یکی دیگر از اهداف این پایان‌نامه شناسایی، تعریف و تفکیک پارامترهای حاکم در حوزه مذکور است.  به‌نظر می‌رسد که فنون یادگیری ماشینی راه‌گشای حل مسائل شرح داده شده در بخش \ref{problem_statement} باشد. به‌همین جهت فراهم آوردن چارچوبی استاندارد برای شکل‌دهی به کارهای آتی، مفید و مثمر ثمر خواهد بود.
به‌طور خلاصه ما چندین فرضیه در این پایان‌نامه درنظر داریم، که تدوین سازوکارهایی برای رد یا تأیید صحت آنها، اهدافِ ما خواهند بود:

\begin{itemize}
	\item{
	استفاده از فنون یادگیری ژرف بالأخص شبکه‌های عصبی مکرر ژرف، در یادگیری خودکار ساختار فایل، امکان‌پذیر و نتیجه‌بخش است.
}

%	\item{
	%استفاده از تولید مبتنی بر گرامر منجر به رسیدن به مسیرهای اجرایی جدید و بهبود میزان پوشش کد آزمون فازی در برنامه‌هایی که فایل با ساختار پیچیده را به عنوان ورودی می‌پذیرند، می‌گردد
%}

\item{
	خودکارسازی کامل فرایند آزمون فازی مبتنی بر گرامر با ترکیب مدل یادگیری (مدل زبانی عصبی) و روش‌های فاز (بد-شکل‌سازی) ورودی، به خوبی میسر می‌شود.
}

\item{
روش‌های ترکیبی تولید داده آزمون، یعنی روش تولید مبتنی بر گرامر به همراه روش تولید مبتنی بر جابه‌جایی، منجر به افزایش پوشش کد
\gls{SUT}
می‌گردند.
}

\item{
	امکان کشف خطاها و آسیب‌پذیری‌های احتمالی موجود در \gls{SUT} از طریق آزمون فازی با داده‌های آزمون تولید شده از طریق مدل‌های یادگیری ژرف، وجود دارد.
}

\end{itemize}

   

\section{روش پیشنهادی و نوآوری‌ها}
در این پایان‌نامه یک روش برای یادگیری خودکار ساختار فایل و سپس تولید داده‌های آزمون بر اساس آن ارایه می‌شود. برای یادگیری از مدل زبانی (\gls{LM})
 که یک مفهوم ابتدایی در پردازش زبان طبیعی (\gls{NLP})،
است استفاده می‌کنیم. مدل زبانی را با استفاده از کلاس خاصی از 
\glspl{DeepNeuralNetwork}
موسوم به شبکه‌ عصبی مکرر (\gls{RNN})، ایجاد می‌کنیم که در نتیجه به آن مدل زبانی عصبی (\gls{NLM}) هم گفته می‌شود. روش ارایه  شده در اینجا، همچنین، بخش‌های غیرمتنی را نیز در آزمون فازی لحاظ می‌کند، به هیچ قالب فایل خاصی وابستگی نداشته و به سبب پیاده‌سازی با زبان پایتون قابلیت اجرا برروی هر ماشینی را دارد. 

روش پیشنهادی در فصل 
\ref{ch:4}،
در سه بخش کلی ارائه شده است. بخش اول به یادگیری ساختار فایل می‌پردازد
(بخش \ref{sec:model})
، بخش دوم روشی برای تولید و بدشکل‌سازی همزمان داده‌های آزمون ارایه می‌دهد 
(بخش \ref{sec:neural_fuzzing_algorithms})
و در نهایت بخش سوم یک فازر کاملاً پیمانه‌ای را معرفی می‌کند که از آن برای آزمون فازی قالب فایل استفاده خواهد شد
(بخش \ref{sec:implementation})
. در حالی که تمرکز اصلی بر روی نحوه تولید داده‌های آزمون است، اما برای انجام آزمون فازی به ابزارهای دیگری مانند تزریق کننده داده آزمون و نیز پایش 
\gls{SUT}  
جهت ثبت خطاهای رخ‌ داده شده نیاز است. نوآوری‌های اصلی روش پیشنهادی به طور خلاصه عبارتند از:
\begin{enumerate}
	\item{
	یادگیری گرامر یا ساختار یک قالب فایل با استفاده از مدل‌های زبانی عصبی،	
}

\item{
	تولید داده‌های آزمون متنی و دودویی همگام با بدشکل‌سازی آنها با استفاده از یک روش ترکیبی،
}

\item{
ایجاد یک فازر قالب فایل و یک مجموعه داده آزمون برای آزمون فازی نرم‌افزارهای 
\gls{PDF}خوان،
}

\item{
	و بررسی و شناسایی پارامترهای مؤثر در یادگیری ساختار فایل با استفاده از فنون یادگیری ژرف.
}

\end{enumerate}

توضیح مبسوط‌تری از نوآوری‌های و دستاوردهای این پایان‌نامه در فصل 
\ref{ch:6}، 
ارایه شده است. در آن فصل همچنین مزایا و معایب فنون یادگیری ژرف در یادگیری ساختار فایل و نیز مزایا و معایب روش پیشنهادی بررسی و بیان شده‌اند. 


\section{اهمیت موضوع}
مانند هر محصول دیگری، نرم‌افزار نیازمند \gls{Test} و راستی‌آزمایی است.  ماهیت غیرقابل لمس و پیچیدگی ذاتی نرم‌افزار سبب می‌شود تا فرایند آزمون آن نیز متفاوت، پیچیده و پرهزینه باشد. اما این دشواری‌ها از اهمیت موضوع آزمون نمی‌کاهد. \gls{Fault}های نرم‌افزاری در مواردی سبب خسارت‌های مالی و جانی جبران ناپذیری شده‌اند. راکت آریـان 5\LTRfootnote{\href{https://en.wikipedia.org/wiki/Ariane\textunderscore5}{https://en.wikipedia.org/wiki/Ariane\textunderscore5}}
 اروپا در سال 1996، تنها 37 ثانیه پس از پرتاب منفجر شد. علت آن وقوع خطا در تبدیل نوع یک عدد ممیز شناور به عدد صحیح بود \cite{ammann2016introduction}. وجود خطا در ماشین پرتودرمانی \lr{Therac-25}\LTRfootnote{\href{https://en.wikipedia.org/wiki/Therac-25}{https://en.wikipedia.org/wiki/Therac-25}}،
سبب کشته شدن دست‌کم سه انسان بر اثر تششع بیش‌از حد پرتو، در سال‌های 1985 تا 1987 شد. مثال‌های دیگری از این قبیل در 
\cite{ammann2016introduction,Dubrova:2013:FD:2462571}
آمده است.

در مواردی وجود خطا منجربه \gls{Vulnerability} می‌شود که امکان سوء استفاده و دسترسی‌های غیرمجاز را به \glspl{Attacker} می‌دهد. \gls{Ransomware} 
\lr{WannaCrypt}\LTRfootnote{\href{https://docs.microsoft.com/en-us/windows/security/threat-protection/wannacrypt-ransomware-worm-targets-out-of-date-systems-wdsi}{https://docs.microsoft.com/en-us/windows/security/threat-protection/wannacrypt-ransomware-worm-targets-out-of-date-systems-wdsi}}
که در نیمه اول سال 2017، بیش از ۲۳۰ هزار رایانه را در ١٥٠ کشور جهان آلوده ساخت، از یک آسیب‌پذیری در هسته نسخه‌های قدیمی، سیستم عامل ویندوز شرکت مایکروسافت بهره‌برداری کرده ‌بود. این باج‌افزار اطلاعات کاربر را رمزنگاری و برای رمزگشایی آن درخواست پرداخت هزینه می‌کرد. شرکت سیمنتک\LTRfootnote{\href{https://www.symantec.com/}{https://www.symantec.com/}}
در گزارش \gls{ISRT} خود در سال 2018\LTRfootnote{\href{https://www.symantec.com/security-center/threat-report}{https://www.symantec.com/security-center/threat-report}} \cite{Symantec2018}، افزایش 600 درصـدی حملات در \gls{InternetOfThings} (اینترنت اشیاء) و افزایش تهدیدات در دیگر حوزه‌های سایبری از جمله تلفن همراه، را اعلام کرده است. در هر حال، کشف خطا و آسیب‌پذیری احتمالی ناشی از آن، در نرم‌‌افزارهایی که به طور گسترده توسط همگان مورد استفاده قرار می‌گیرند، مثل سیستم‌عامل‌ها، مرورگرهای وب، \gls{PDF}خوان‌ها و غیره، بسیار حائز اهمیت است؛ زیرا، در صورت برطرف نشدن آن خطر وقوع حملاتی مشابه حملات بالا دور از انتظار نخواهد بود.


هنگامی که نرم‌افزارها بزرگ می‌شوند، آزمون دستی پاسخ‌گو نیست و خودکارسازی آزمون اهمیت می‌یابد. آزمون فازی همان‌طور که در ابتدای فصل بیان شد، به عنوان یک فن مؤثر آزمون نرم‌افزار در شناسایی خطاهای حافظه و آسیب‌پذیری‌ها شناخته شده است. برای مثال چرخه حیات امن نرم‌افزار (\gls{SDL}) شرکت مایکروسافت
\LTRfootnote{\href{https://www.microsoft.com/en-us/sdl}{https://www.microsoft.com/en-us/sdl}}، در مرحله \gls{Verification}، استفاده از آزمون فازی را به عنوان یک روش استاندارد، اجباری می‌کند \cite{Corporation2010}. آزمون فازی \gls{WhiteBox} (رجوع کنید به بخش \ref{box_view})، حدود یک سوم کل آسیب‌پذیری‌های شناخته شده در سیستم عامل ویندوز 7 این شرکت را کشف کرده است \cite{Godefroid:2012:SWF:2090147.2094081}. شرکت گوگل در سال 2012، اطلاعاتی راجع‌به ابزار \lr{ClusterFuzz} خود منتشر کرد که از آن برای آزمون فازی پروژه‌های \lr{ Chromium}\LTRfootnote{\href{https://www.chromium.org/}{https://www.chromium.org/}} (شامل  \lr{Chromium OS} و مرورگر وب \lr{Chromium}) استفاده می‌کند \cite{Kettunen2014}. این شرکت همچنین به افرادی که موفق به کشف آسیب‌پذیری در پروژه‌های‌ نام‌برده شوند، جوایزی اهدا می‌کند.


تولید داده آزمون را بایستی مهم‌ترین مرحله در آزمون فازی دانست؛ چراکه داده‌هایی که نرم‌افزار با آنها آزمون می‌شود عامل اصلی اجرا شدن کد‌های قسمت‌های مختلف \gls{SUT} است و در صورتی که خطایی در آنها وجود داشته باشد، تنها از این طریق است که خود را نشان می‌دهد. البته باید بدین مسئله توجه کرد که اجرای کد خطادار شرط لازم برای آشکارسازی خطا است ولی کافی نیست و روش تولید داده‌های آزمون، می‌بایست شرایط خاص بدشکل بودن را نیز محیا کند. تولید داده مبتنی بر گرامر، مؤثرترین روش آزمون برنامه‌هایی با ساختار ورودی پیچیده است \cite{Chen2018}. موارد بیان شده در این بخش، به‌خوبی اهمیت موضوع تولید خودکار داده آزمون در آزمون فازی و لزوم ارایه روش‌های جدید را توجیه کرده و انگیزه کافی را برای پژوهش در این زمینه ایجاد می‌کنند.   




\section{ساختار پایان‌نامه}

این پایان‌نامه در شش فصل و دو پیوست تنظیم شده است و ساختار ادامه آن به  قرار زیر است. در فصل
%\hyperref[chapter2]{فصل دوم}
\ref{chapter2}
ادبیات موضوع شامل آزمون نرم‌افزار، آزمون ‌فازی و یادگیری ژرف را مطرح می‌کنیم. در این فصل ابتدا معیارهای سنجش کیفیت آزمون و چگونگی محاسبه‌ آنها را توضیح داده، سپس به معرفی آزمون فازی، فرایند کلی  و روش‌های تولید داده آزمون در آن می‌پردازیم. در بخش پایانی مباحث یادگیری ژرف را با تمرکز بر مفاهیم مرتبط با یادگیری ساختار فایل، عنوان خواهیم کرد.  


در فصل \ref{related_work} به پیشینه پژوهش و بیان کارهای مرتبط در تولید خودکار داده آزمون و نقـد و بررسی آنها می‌پردازیم. به‌طور خلاصه برخی راه حل‌های دیگران برای مسائل مطرح شده در بخش \ref{problem_statement} را معرفی و  سپس مشکلات آنها را بیان می‌کنیم. روش پیشنهادی در راســتای حل این مسائل و ارزیابی ما در مقایسه با نتایج ارائه شده قبلی در این فصل خواهد بود.

در فصل \ref{ch:4} روش پیشنهادی خود را برای تولید داده آزمون مطرح می‌کنیم. روش پیشنهادی در این فصل، همان‌طور که بدان اشاره شد، یک روش تولید مبتنی بر مدل‌های زبانی است که ما جابه‌جایی‌های تصادفی را نیز به آن اضافه کرده‌ و روشی ترکیبی خلق نموده‌ایم. در  همین فصل، ما دو الگوریتم جدید را برای فاز داده‌های آزمون معرفی می‌کنیم.

در فصل \ref{ch:5} معیارهای ارزیابی روش پیشنهادی، چیدمان آزمایش‌ها و نتایج حاصل از اجرای آنها را ذکر خواهیم کرد. مورد مطالعاتی ما در آزمایش‌های این فصل نرم‌افزار 
\lr{MuPDF}\LTRfootnote{\href{https://mupdf.com/}{https://mupdf.com/}} \cite{MuPDF2018}
 و قالب فایل \lr{PDF} است که در ابتدای فصل آنها را مختصر معرفی خواهیم کرد. 

در نهایت فصل \ref{ch:6} را به بیان نتیجه‌گیری، یافته‌ها و نوآوری‌های پایان‌نامه، محدودیت‌های روش پیشنهادی و کارهای قابل انجام در آینده اختصاص داده‌ایم. همچنین در پیوست \ref{appendix:1} ساختار فایل \lr{PDF} و در پیوست \ref{appendix:2} جزئیات پیاده‌سازی محصول نهایی پایان‌نامه را درج کرده‌ایم.



